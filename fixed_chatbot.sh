#!/bin/bash
# Test the fixed GenPipes RAG chatbot

echo "üß™ Testing Fixed GenPipes RAG Chatbot"
echo "======================================"

cd ~/genpipes-rag-chatbot  # Adjust path as needed
source venv/bin/activate

echo "1Ô∏è‚É£ Testing Ollama (should respond quickly now)..."
timeout 15s ollama run llama2 "Say 'Ollama working'" 2>/dev/null && echo "‚úÖ Ollama OK" || echo "‚ùå Ollama timeout"

echo ""
echo "2Ô∏è‚É£ Testing ChromaDB..."
python -c "
import chromadb
try:
    client = chromadb.PersistentClient(path='genpipes_vectordb')
    collection = client.get_collection('genpipes_docs')
    print(f'‚úÖ ChromaDB OK - {collection.count()} documents')
except Exception as e:
    print(f'‚ùå ChromaDB error: {e}')
"

echo ""
echo "3Ô∏è‚É£ Quick embedding test..."
python -c "
from sentence_transformers import SentenceTransformer
import time
start = time.time()
model = SentenceTransformer('all-MiniLM-L6-v2')
elapsed = time.time() - start
print(f'‚úÖ Embedding model loaded in {elapsed:.1f}s')
"

echo ""
echo "4Ô∏è‚É£ Testing the fixed chatbot..."
echo "Starting chatbot - it should load much faster now!"
echo ""
echo "Try asking: 'How do I run RNA-seq pipeline?'"
echo "Expected: Should respond in 10-30 seconds (not hang)"
echo ""
echo "If it works, you'll see:"
echo "- ‚úÖ Connected! Found XXX documents"
echo "- ‚úÖ Ollama ready with model: llama2"  
echo "- üîç Searching documentation... ‚úÖ"
echo "- üß† Generating response... ‚úÖ"
echo ""
echo "üöÄ Starting fixed chatbot now..."
echo "==============================="

python fixed_rag_chatbot.py --model llama2
